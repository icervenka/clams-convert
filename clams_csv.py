#!/usr/bin/env python3

import pandas as pd
import numpy as np
import re
import glob
import sys
import datetime
import argparse
import os

# set default directory to current working directory
wd = os.getcwd()
input_filepath = wd
output_filepath = wd

# parse input and output arguments arguments
parser = argparse.ArgumentParser(description = "Concatenate CSV files from CLAMS to one file for analysis by clams-vis")

parser.add_argument('-i', '--input', help = "Path to input files")
parser.add_argument('-o', '--output', help = "Path where the output will be stored")
args = parser.parse_args()

if args.input:
    input_filepath = args.input

if args.output:
    output_filepath = args.output

# array to be populated with list of files
file_list = []

# data frame to be appended with individual animal data
data_frame_final = pd.DataFrame()

# find csv files to process or exit
for file in glob.glob(str(input_filepath)+"/*.CSV"):
    file_list.append(file)

if len(file_list) == 0:
    sys.exit("No CSV files to process")

# name of the columns in the csv file generated by CLAMS machine
column_names = ["Interval", "Date/Time", "Volume O2", "O2 In",	"O2 Out","Delta O2", "Accumulated O2",
                "Volume CO2", "CO2 In", "CO2 Out", "Delta CO2", "Accumulated CO2", "RER", "Heat", "Flow",	
                "Feed Weight 1", "Feed Acc. 1", "Drink Weight 1",	"Drink Acc. 1", "X Total", "X Ambulatory", "Y Total",	
                "Y Ambulatory", "Z Total", "Light/Dark"]

# columns reordered to match the shinyapps utility
use_columns = [0]+list(range(2,16))+list(range(17,26))+[31]

# RE patterns to identify lines of interest in csv data
subject_id_pattern = re.compile("Subject ID") 
start_data_pattern = re.compile(":DATA") # start of data header
csv_file_pattern = re.compile("Oxymax CSV File") # animal file type
events_pattern = re.compile(":EVENTS") # start of events

# repeat for all csv files in file list
for csv in file_list:
    
    subject_id = None
    start_data_line = None
    end_data_line = None
    csv_file_type = False
    
    events_line = None
    events = {}
    
    # variable will hold array of csv lines
    text = []
    
    # determine the line locations for RE patterns of interest and set corresponding line numbers
    with open(csv, "r") as file:
        text = file.read().splitlines()
        text = [line for line in text if len(line) > 0] # remove empty lines from csv file
        
        for i, line in enumerate(text):
            if re.match(csv_file_pattern, line):
                csv_file_type = True
            if re.match(subject_id_pattern, line):
                subject_id = line
            if re.match(start_data_pattern, line):
                start_data_line = i+5  # might change in CLAMS system updates
            if re.match(events_pattern, line):
                events_line = i+4 # might change in CLAMS system updates
                end_data_line = i-1
      
    # skip if csv file is a parameter file not an animal file
    if csv_file_type == False:
        print("Skipping: "+csv+" - Not an animal data file")
        continue
    else: 
        print("Processing: "+csv)
    
    # parse subject ID
    subject_id = subject_id.strip().split(',')[1]
    
    # split lines from array on comma
    records = [x.split(',') for x in text]
    # generate a numpy array that would converted to data frame
    data_records = np.array(records[start_data_line:end_data_line])
    
    # data frame of records    
    data = pd.DataFrame(data_records)
    data = data.iloc[:,use_columns] # use only selected columns
    data.columns = column_names
    
    # reorder columns to match shinyapps utility specification
    cols = data.columns.tolist() 
    cols = cols[:2]+cols[-1:]+cols[2:-1]
    data = data[cols]
    
    # rename Light/Dark phase to match shinyapps utility specification
    data.iloc[:,2].replace("ON", "Light", inplace = True)
    data.iloc[:,2].replace("OFF", "Dark", inplace = True)
    
    # insert subject ID column and Event Log column
    data.insert(loc = 0, column = "Subject", value = subject_id)
    data.insert(loc = len(data.columns), column = "Event Log", value = "") # starts as empty string
    
    # parse events from csv file
    event_records = np.array(records[events_line:])
    
    # select Intervals and Description for data frame
    events = pd.DataFrame(event_records[:,[0,3]])
    events.columns = ["Interval", "Event Log"] # rename
    
    # convert intervals to numeric and set as index for merging to data dataframe
    events.Interval = events.Interval.apply(pd.to_numeric)
    events = events.set_index("Interval")
    
    # merge events to data dataframe keeping intervals without description as an empty string
    data.iloc[list(events.index), [-1]] = events["Event Log"]

    #TODO set float precision
    
    # append processed files to final data frame
    if data_frame_final.empty:
        data_frame_final = data
    else:
        data_frame_final = data_frame_final.append(data)
        
print("Processing complete")

# export the final data frame
filename = str(datetime.date.today())+"_result_all.csv"
with open(str(output_filepath)+filename, "w") as file:
    data_frame_final.to_csv(file, index = False)
  
print("\n")
print("Results were saved to file: "+filename)
